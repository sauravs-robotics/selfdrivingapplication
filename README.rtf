{\rtf1\ansi\ansicpg1252\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 ##BASICS OF PROJECT\
\
MATLAB connection with raspberry pi over bluetooth is utilized to divide computational power to achieve both steering and object detection\
\
Hardware used:\
2 L293N motor drivers, 1 for 2 right wheels, 1 for 2 left wheels \
4 DC motors (1 for each wheel)\
1 Arduino Mega to control motors (and encoders, but not yet incorporated)\
1 Raspberry PI 3+\
Plastic car kit to mount raspberry pi and Arduino and motors\
1 webcam for object detection\
1 camera board for higher resolution steering using lane lines \
\
Software needed to run:\
Python with necessary libraries listed in \'91road_signs.py\'92\
MATLAB with Deep learning, Arduino and Raspberry Pi libraries \
\
helperfunctions:\
find_lane_angles: finds longest line which is then inputted as the line to associate with steering correctly\
Camera2steering.m: converts outputted angle using Houghlines to angle from car\'92s POV\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 setMotor.m: Arduino motor connections to give speeds to left side wheels and right side wheels \
traffic_sign_response.m: if a road sign is found in image, gives correct response (ie stop at stop sign)\
\
RoadSigns.py:\
Uses a very cut down CNN (still 95% accurate!) to lower computations to run in real time on raspberry Pi\
German Road Signs dataset used to train model\
MUST RUN THIS FILE FIRST to obtain \'91objdetection.h5\'92 file, which is trained h5 keras file that will be used in the MATLAB file to classify objects\
NOTE: current version1 using only detection, no localization; but future versions WILL have this incorporated \
Only ones used on current test track: stop signs, traffic light ahead, speed limits to also lower computational energy given hardware limitations \
\
self_drive.m:\
Combines everything to do steering based on camera board and computer vision algorithm obtaining velocity commands for each motor; uses trained model from keras to detect and change speed of car appropriately based on the sign detected in current image\
Currently running in almost real time using MATLAB\
\
NOTE: currently car is directly wired to computer to run MATLAB while driving, but future version will incorporate bluetooth chip connected to Arduino to allow MATLAB to remotely compute steering computations before sending command back to Arduino (theoretically should still run in real time); raspberry pi connected to computer via WiFi \
\
}