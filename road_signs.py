# -*- coding: utf-8 -*-
"""road_signs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iwKOj2dyWrtvN10kMS-Z8G9SXzi8oAST
"""

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers import Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
import pickle 
import pandas as pd
import random
import h5py

np.random.seed(0)

!git clone https://bitbucket.org/jadslim/german-traffic-signs

!ls german-traffic-signs

with open('german-traffic-signs/train.p','rb') as f:
  train_data = pickle.load(f)
with open('german-traffic-signs/valid.p','rb') as f:
  val_data = pickle.load(f)
with open('german-traffic-signs/train.p','rb') as f:
  test_data = pickle.load(f) 
print(type(train_data))
X_train, y_train = train_data['features'], train_data['labels']
X_val, y_val = val_data['features'], val_data['labels']
X_test, y_test = test_data['features'], test_data['labels']

assert(X_train.shape[0] == y_train.shape[0]), "number of images is not equal to number of labels"
assert(X_val.shape[0] == y_val.shape[0]), "number of images is not equal to number of labels"
assert(X_test.shape[0] == y_test.shape[0]), "number of images is not equal to number of labels"
assert(X_train.shape[1:] == (32, 32, 3)), "dimension of images are incorrect"
assert(X_val.shape[1:] == (32, 32, 3)), "dimension of images are incorrect"
assert(X_test.shape[1:] == (32, 32, 3)), "dimension of images are incorrect"
tr = X_train.shape
va = X_val.shape
te = X_test.shape

signs = pd.read_csv('german-traffic-signs/signnames.csv')

num_of_samples = []
 
cols = 5
num_classes = 43 
 
fig, axs = plt.subplots(nrows=num_classes, ncols = cols, figsize=(5, 50))
fig.tight_layout()
for i in range(cols):
    for j, row in signs.iterrows():
        x_selected = X_train[y_train == j]
        axs[j][i].imshow(x_selected[random.randint(0, len(x_selected)-1), :, :], cmap=plt.get_cmap("gray"))
        axs[j][i].axis("off")
        if i == 2:
            axs[j][i].set_title(str(j) + "-" + row["SignName"])
            num_of_samples.append(len(x_selected))
        #j = (index,series)

print(num_of_samples)
plt.figure(figsize=(12, 4))
plt.bar(range(0, num_classes), num_of_samples)
plt.title("Distribution of the training dataset")
plt.xlabel("Class number")
plt.ylabel("Number of images")

import cv2

def preprocessing(img):
  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  img = cv2.equalizeHist(img)
  img = img/255 
  return img

X_train = np.array(list(map(preprocessing,X_train)))
X_val = np.array(list(map(preprocessing,X_val)))
X_test = np.array(list(map(preprocessing,X_test)))
plt.imshow(X_train[random.randint(0,len(X_train)-1)])
plt.axis("off")

X_train.reshape(tr[0], 32, 32, 1)
X_val.reshape(va[0], 32, 32, 1)
X_train.reshape(te[0], 32, 32, 1)

from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2, shear_range=0.1, rotation_range=20)
datagen.fit(X_train)

batches = datagen.flow(X_train, y_train, batch_size = 20)
x_batch, y_batch = next(batches)

y_train = to_categorical(Y_train, num_classes)
y_val = to_categorical(Y_val, num_classes)
y_test = to_categorical(Y_test, num.classes)

def cnn_model:
    model = Sequential()
    model.add(Conv2D(60, (5, 5), input_shape=(32, 32, 1), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2))) 
    model.add(Conv2D(30, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2))) 
    model.add(Flatten())
    model.add(Dense(500, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
  # Compile model
    model.compile(Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])
    return model

model.fit(X_train,y_train, epochs=10, validation_data = (X_val,y_val), batch_size=400, verbose= 1, shuffle = 1)
model.fitgenerator(datagen.flow(X_train,y_train, epochs=10, batch_size=50), steps_per_epoch = 2000, epochs = 10, validation_data = (X_val,y_val), shuffle = 1)

hf = h5py.File('objdetection.h5', 'w')